{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholars import *\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=',')\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=',')\n",
    "X_test = np.genfromtxt('data/X_test.txt', delimiter=',')\n",
    "X, Y = ml.shuffleData(X, Y)\n",
    "Xtr,Xva,Ytr,Yva = ml.splitData(X,Y,0.75) \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackPredictions(predictions):\n",
    "    num_data = len(predictions[0])\n",
    "    finalPrediction = [0]*num_data\n",
    "    for j in range(num_data):\n",
    "        finalPrediction[j] = np.mean(np.array(predictions)[:, j])\n",
    "    return finalPrediction\n",
    "\n",
    "\n",
    "def convertToFinalPredictions(pred):\n",
    "    final_pred = []\n",
    "    for i in pred:\n",
    "        if i>0.5 or i == True:\n",
    "            final_pred.append(1)\n",
    "        else:\n",
    "            final_pred.append(0)\n",
    "\n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINS LEARNER\n",
    "gradientBoostTR = GradientBoost(Xtr,Ytr)\n",
    "logistic41featuresTR = LogisticRegression().fit(Xtr[:,:41],Ytr)\n",
    "adaBoosTR = AdaBoost(Xtr,Ytr, learning_rate=2)\n",
    "gradientBoost2TR = GradientBoost2(Xtr,Ytr)\n",
    "randomForestTR = RandomForest(Xtr,Ytr,nFeatures = 50, maxDepth = 15, minLeaf = 4, number_of_learner=25)\n",
    "randomForest2TR = RandomForest2(Xtr,Ytr)\n",
    "knn28categoricalTR = ml.knn.knnClassify(Xtr[:,41:69],Ytr)\n",
    "gradient12Boost2TR = GradientBoost2(Xtr[:,:69], Ytr)\n",
    "gradient23Boost2TR = GradientBoost2(Xtr[:,41:], Ytr)\n",
    "newXtr = np.hstack((Xtr[:,:41],Xtr[:,69:]))    \n",
    "gradient13Boost2TR = GradientBoost2(newXtr, Ytr)\n",
    "\n",
    "gradientBoost = GradientBoost(X,Y)\n",
    "logistic41features = LogisticRegression().fit(X[:,:41],Y)\n",
    "knn28categorical = ml.knn.knnClassify(X[:,41:69],Y)\n",
    "adaBoost = AdaBoost(X,Y, learning_rate=2)\n",
    "gradientBoost2 = GradientBoost2(X,Y)\n",
    "randomForest = RandomForest(X,Y,nFeatures = 50, maxDepth = 15, minLeaf = 4, number_of_learner=25)\n",
    "randomForest2 = RandomForest2(X,Y)\n",
    "gradient12Boost2 = GradientBoost2(X[:,:69], Y)\n",
    "gradient23Boost2 = GradientBoost2(X[:,41:], Y)\n",
    "newX = np.hstack((X[:,:41],X[:,69:]))    \n",
    "gradient13Boost2 = GradientBoost2(newX, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUNS PREDICTION\n",
    "gradientPredictionTR = gradientBoostTR.predict(Xva)[:, 1]\n",
    "adaPredictionTR = adaBoosTR.predict(Xva)[:, 1]\n",
    "gradientPrediction2TR = gradientBoost2TR.predict(Xva)\n",
    "forestPredictionTR = randomForestTR.predict(Xva)\n",
    "forest2PredictionTR = randomForest2TR.predict(Xva)\n",
    "logistic41PredictionTR = logistic41featuresTR.predict(Xva[:,:41])\n",
    "knn28PredictionTR = knn28categoricalTR.predict(Xva[:,41:69])\n",
    "newXva = np.hstack((Xva[:,:41],Xva[:,69:]))\n",
    "gradient13PredictionTR = gradient13Boost2TR.predict(newXva)  \n",
    "gradient23PredictionTR = gradient23Boost2TR.predict(Xva[:,41:])\n",
    "gradient12PredictionTR = gradient12Boost2TR.predict(Xva[:,:69])\n",
    "\n",
    "gradientPrediction = gradientBoost.predict(X_test)[:, 1]\n",
    "adaPrediction = adaBoost.predict(X_test)[:, 1]\n",
    "gradientPrediction2 = gradientBoost2.predict(X_test)\n",
    "forestPrediction = randomForest.predict(X_test)\n",
    "forest2Prediction = randomForest2.predict(X_test)\n",
    "logistic41Prediction = logistic41features.predict(X_test[:,:41])\n",
    "knn28Prediction = knn28categorical.predict(X_test[:,41:69])\n",
    "newXtest = np.hstack((X_test[:,:41],X_test[:,69:]))\n",
    "gradient13Prediction = gradient13Boost2.predict(newXtest)  \n",
    "gradient23Prediction = gradient23Boost2.predict(X_test[:,41:])\n",
    "gradient12Prediction = gradient12Boost2.predict(X_test[:,:69])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "forest2Prediction ERROR:  0.3394396551724138\nforestPrediction ERROR:  0.3556034482758621\ngradientPrediction2 ERROR:  0.3351293103448276\ngradientPrediction ERROR:  0.34213362068965514\nadaPrediction ERROR:  0.42403017241379315\nLOGISTIC ERROR:  0.4385775862068966\nknn28PredictionTR ERROR:  0.4951508620689655\ngradient13PredictionTR ERROR:  0.33728448275862066\ngradient12PredictionTR ERROR:  0.33836206896551724\ngradient23PredictionTR ERROR:  0.4132543103448276\n"
     ]
    }
   ],
   "source": [
    "\n",
    "forest2PredictionTR = convertToFinalPredictions(forest2PredictionTR)\n",
    "print(\"forest2Prediction ERROR: \",1-sum(forest2PredictionTR==Yva)/float(len(Yva)))\n",
    "\n",
    "forestPredictionTR = convertToFinalPredictions(forestPredictionTR)\n",
    "print(\"forestPrediction ERROR: \",1-sum(forestPredictionTR==Yva)/float(len(Yva)))\n",
    "\n",
    "gradientPrediction2TR = convertToFinalPredictions(gradientPrediction2TR)\n",
    "print(\"gradientPrediction2 ERROR: \",1-sum(gradientPrediction2TR==Yva)/float(len(Yva)))\n",
    "\n",
    "gradientPredictionTR = convertToFinalPredictions(gradientPredictionTR)\n",
    "print(\"gradientPrediction ERROR: \",1-sum(gradientPredictionTR==Yva)/float(len(Yva)))\n",
    "\n",
    "adaPredictionTR = convertToFinalPredictions(adaPredictionTR)\n",
    "print(\"adaPrediction ERROR: \",1-sum(adaPredictionTR==Yva)/float(len(Yva)))\n",
    "\n",
    "logistic41PredictionTR = convertToFinalPredictions(logistic41PredictionTR)\n",
    "print(\"LOGISTIC ERROR: \", 1-sum(logistic41PredictionTR==Yva)/float(len(Yva)))\n",
    "\n",
    "knn28PredictionTR = convertToFinalPredictions(knn28PredictionTR)\n",
    "print(\"knn28PredictionTR ERROR: \", 1-sum(knn28PredictionTR==Yva)/float(len(Yva)))\n",
    "\n",
    "\n",
    "gradient13PredictionTR = convertToFinalPredictions(gradient13PredictionTR)\n",
    "print(\"gradient13PredictionTR ERROR: \",1-sum(gradient13PredictionTR==Yva)/float(len(Yva)))\n",
    "\n",
    "gradient12PredictionTR = convertToFinalPredictions(gradient12PredictionTR)\n",
    "print(\"gradient12PredictionTR ERROR: \",1-sum(gradient12PredictionTR==Yva)/float(len(Yva)))\n",
    "\n",
    "gradient23PredictionTR = convertToFinalPredictions(gradient23PredictionTR)\n",
    "print(\"gradient23PredictionTR ERROR: \",1-sum(gradient23PredictionTR==Yva)/float(len(Yva)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.19029851 0.18532338 0.18781095 0.18221393 0.16666667 0.08768657]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jBlend = [gradientBoost2TR,randomForest2TR,gradient13Boost2TR,gradientBoostTR, gradient12Boost2TR,adaBoosTR]\n",
    "jBlendPred = np.array([gradientPrediction2TR,forest2PredictionTR,gradient13PredictionTR,gradientPredictionTR,forestPredictionTR,adaPredictionTR])\n",
    "def calculateWeight(predictions,Yva):\n",
    "    # allagreeCounter = 0\n",
    "    # allagreeButWrong = 0\n",
    "    # mostAgree = 0\n",
    "    # mostAgreeButWrong = 0\n",
    "    # equalProb = 0\n",
    "    # adaWrong = 0\n",
    "    numOfleaners = len(predictions)\n",
    "    weight = np.zeros(numOfleaners)\n",
    "    for indx, trueClass in enumerate(Yva):\n",
    "        avgPredict = np.mean(predictions[:,indx])\n",
    "        # if avgPredict == 1 or avgPredict == 0: # if all the learners agree or disagree we can't change the weight in any ways\n",
    "        #     pass\n",
    "        # if avgPredict != 0.5: # optimized heavily because there is a majority here\n",
    "        #     if avgPredict == 5/6:\n",
    "        #         for i in range(numOfleaners):\n",
    "        #             if predictions[i,indx] == trueClass:\n",
    "        #                 weight[i] += 1\n",
    "        #             else:\n",
    "        #                 weight[i] -= 5\n",
    "        #     elif avgPredict == 1/6:\n",
    "        #         for i in range(numOfleaners):\n",
    "        #             if predictions[i,indx] == trueClass:\n",
    "        #                 weight[i] += 500\n",
    "        #             else:\n",
    "        #                 weight[i] -= 1\n",
    "        #     elif avgPredict == 2/6:\n",
    "        #         for i in range(numOfleaners):\n",
    "        #             if predictions[i,indx] == trueClass:\n",
    "        #                 weight[i] += 200\n",
    "        #             else:\n",
    "        #                 weight[i] -= 1\n",
    "        #     elif avgPredict == 4/6:\n",
    "        #         for i in range(numOfleaners):\n",
    "        #             if predictions[i,indx] == trueClass:\n",
    "        #                 weight[i] += 1\n",
    "        #             else:\n",
    "        #                 weight[i] -= 2\n",
    "        # else: # can be optimized slightly. half  of the learners agree and half disagree\n",
    "            # for i in range(numOfleaners):\n",
    "            #     if predictions[i,indx] == trueClass:\n",
    "            #         weight[i] += 1\n",
    "            #     else:\n",
    "            #         weight[i] -= 1\n",
    "        for i in range(numOfleaners):\n",
    "            if predictions[i,indx] == trueClass:\n",
    "                weight[i] += 1\n",
    "            else:\n",
    "                weight[i] -= 1\n",
    "            \n",
    "    #     if avgPredict == 1 or avgPredict == 0:\n",
    "    #         allagreeCounter +=1\n",
    "    #         if avgPredict != trueClass:\n",
    "    #             allagreeButWrong +=1\n",
    "    #     elif avgPredict == 5/6 or avgPredict == 1/6 or avgPredict == 2/6 or avgPredict == 4/6:\n",
    "    #         mostAgree+=1\n",
    "    #         if avgPredict > 0.5 and trueClass == 0 or avgPredict < 0.5 and trueClass ==1:\n",
    "    #             mostAgreeButWrong +=1\n",
    "    #     else:\n",
    "    #         equalProb += 1\n",
    "    \n",
    "\n",
    "    # print(f\"Percent that all agree: {allagreeCounter/len(Yva)}, all agree but wrong: {allagreeButWrong/len(Yva)}\")\n",
    "    # print(f\"Percent that can be heavily optimize: {mostAgree/len(Yva)}, most agree but wrong: {mostAgreeButWrong/len(Yva)}\")\n",
    "    # print(f\"Percent that can be slightly optimize: {equalProb/len(Yva)}\")\n",
    "    # print(len(Yva))\n",
    "    # print(weight)\n",
    "    return weight/sum(weight)\n",
    "    #     weight = np.array([1/len(predictions)]*len(predictions))\n",
    "weight = calculateWeight(jBlendPred,Yva)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeBlendErr(pred,weight):\n",
    "    result = 0\n",
    "    for i in range(len(pred)):\n",
    "        result += np.array(pred[i]) * weight[i]\n",
    "    printFinalVaErr(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3275862068965517\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "computeBlendErr(jBlendPred,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "jBlendPrediction = 0.19343618   *np.array(gradientPrediction2) +0.19222626  * np.array(forest2Prediction) + 0.18436177 * np.array(gradient13Prediction)+ 0.18935269 *np.array(gradientPrediction)+0.17876588 *np.array(forestPrediction)+0.06185723 *np.array(adaPrediction)\n",
    "\n",
    "Y_test = np.vstack((np.arange(X_test.shape[0]), jBlendPrediction)).T\n",
    "# Output a file with two columns, a row ID and a confidence in class 1:\n",
    "np.savetxt('JBlendPredictions.txt', Y_test, '%d, %.2f',header='ID,Predicted', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalPrediction = stackPredictions([adaPrediction, forestPrediction, gradientPrediction, forest2Prediction, gradientPrediction2])\n",
    "\n",
    "#BEST\n",
    "#finalPrediction = 0.15*np.array(adaPrediction)+0.1*np.array(forestPrediction)+ 0.3*np.array(forest2Prediction) + 0.15*np.array(gradientPrediction) + 0.3*np.array(gradientPrediction2)\n",
    "#BEST\n",
    "\n",
    "#finalPrediction = 0.3*np.array(adaPrediction)+0*np.array(forestPrediction)+ 0.1*np.array(forest2Prediction) + 0.1*np.array(gradientPrediction) + 0.5*np.array(gradientPrediction2)\n",
    "#finalPrediction = 0.1*np.array(adaPrediction) + 0.05*np.array(forestPrediction)+ 0.2*np.array(forest2Prediction) + 0.2*np.array(gradientPrediction) + 0.35*np.array(gradientPrediction2) + 0.1*np.array(logistic41Prediction)\n",
    "\n",
    "#finalPrediction = 0.1*np.array(adaPrediction) + 0.05*np.array(forestPrediction)+ 0.2*np.array(forest2Prediction) + 0.2*np.array(gradientPrediction) + 0.42*np.array(gradientPrediction2) + 0.02*np.array(logistic41Prediction) + 0.01*np.array(knn28Prediction)\n",
    "\n",
    "finalPredictionBESTtr = 0.15*np.array(adaPredictionTR)+0.1*np.array(forestPredictionTR)+ 0.3*np.array(forest2PredictionTR) + 0.15*np.array(gradientPredictionTR) + 0.3*np.array(gradientPrediction2TR)\n",
    "finalPredictionTR = 0.15*np.array(adaPredictionTR)+0.1*np.array(forestPredictionTR)+ 0.3*np.array(forest2PredictionTR) + 0.2*np.array(gradientPredictionTR) + 0.25*np.array(gradientPrediction2TR)\n",
    "finalPrediction = 0.05*np.array(adaPrediction)+0.1*np.array(forestPrediction)+ 0.15*np.array(forest2Prediction) + 0.15*np.array(gradientPrediction) + 0.25*np.array(gradientPrediction2) + 0.125*np.array(gradient13Prediction) + 0.125*np.array(gradient12Prediction)+ 0.05*np.array(gradient23Prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFinalVaErr(finalPrediction):\n",
    "    errCount = 0\n",
    "    ndata=len(finalPrediction)\n",
    "    for i in range(ndata):\n",
    "        if(not ((finalPrediction[i]<0.5 and Yva[i]<0.5) or (finalPrediction[i]>0.5 and Yva[i]>0.5))):\n",
    "            errCount += 1\n",
    "    print(errCount/float(ndata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3394396551724138\n"
     ]
    }
   ],
   "source": [
    "printFinalVaErr(finalPredictionBESTtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.33459051724137934\n"
     ]
    }
   ],
   "source": [
    "printFinalVaErr(finalPredictionTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.vstack((np.arange(X_test.shape[0]), finalPrediction)).T\n",
    "# Output a file with two columns, a row ID and a confidence in class 1:\n",
    "np.savetxt('FinalPredictions.txt', Y_test, '%d, %.2f',header='ID,Predicted', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking outputs\n",
    "outputs = [forest2PredictionTR, forestPredictionTR, gradientPrediction2TR, gradientPredictionTR, adaPredictionTR, logistic41PredictionTR, knn28PredictionTR, gradient13PredictionTR, gradient12PredictionTR, gradient23PredictionTR]\n",
    "#outputs = [forest2PredictionTR, forestPredictionTR, gradientPrediction2TR, gradientPredictionTR, adaPredictionTR]\n",
    "\n",
    "new_outputs = []\n",
    "for i in outputs:\n",
    "    new_outputs.append([[j] for j in i])\n",
    "xMetaTR = np.hstack((np.array(new_outputs)))\n",
    "\n",
    "\n",
    "outputs = [forest2Prediction, forestPrediction, gradientPrediction2, gradientPrediction, adaPrediction, logistic41Prediction, knn28Prediction, gradient13Prediction, gradient12Prediction, gradient23Prediction]\n",
    "new_outputs = []\n",
    "for i in outputs:\n",
    "    new_outputs.append([[j] for j in i])\n",
    "xMeta = np.hstack((np.array(new_outputs)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_gradient2 = GradientBoost2(xMetaTR, Yva)\n",
    "stacked_gradient = GradientBoost(xMetaTR, Yva)\n",
    "stacked_ada = AdaBoost(xMetaTR, Yva)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_forest2 = RandomForest2(xMetaTR, Yva)\n",
    "stacked_forest = RandomForest(xMetaTR, Yva, nFeatures = 50, maxDepth = 15, minLeaf = 4, number_of_learner=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_gradient_predict = stacked_gradient.predict(xMeta)[:,1]\n",
    "stacked_gradient2_predict = stacked_gradient2.predict(xMeta)\n",
    "stacked_ada_predict = stacked_ada.predict(xMeta)[:, 1]\n",
    "stacked_forest2_predict = stacked_forest2.predict(xMeta)\n",
    "stacked_forest_predict = stacked_forest.predict(xMeta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalPrediction = 0.15*np.array(stacked_ada_predict)+0.1*np.array(stacked_forest_predict)+ 0.3*np.array(stacked_forest2_predict) + 0.15*np.array(stacked_gradient_predict) + 0.3*np.array(stacked_gradient2_predict)\n",
    "\n",
    "#finalPrediction = 0.25*np.array(stacked_forest_predict)+ 0.25*np.array(stacked_forest2_predict) + 0.25*np.array(stacked_gradient_predict) + 0.25*np.array(stacked_gradient2_predict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final1 = 0.15*np.array(stacked_ada_predict)+0.1*np.array(stacked_forest_predict)+ 0.3*np.array(stacked_forest2_predict) + 0.15*np.array(stacked_gradient_predict) + 0.3*np.array(stacked_gradient2_predict)\n",
    "final2 = 0.15*np.array(adaPrediction)+0.1*np.array(forestPrediction)+ 0.3*np.array(forest2Prediction) + 0.15*np.array(gradientPrediction) + 0.3*np.array(gradientPrediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPrediction = 0.4*final1 + 0.6*final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.36234344 0.21815255 0.53636606 ... 0.4712536  0.8746315  0.44363959]\n[0.3880978  0.23610827 0.52470947 ... 0.46591101 0.8607841  0.47953562]\n"
     ]
    }
   ],
   "source": [
    "print(finalPrediction)\n",
    "print(final2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.36234344 0.21815255 0.53636606 ... 0.4712536  0.8746315  0.44363959]\n"
     ]
    }
   ],
   "source": [
    "print(finalPrediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}