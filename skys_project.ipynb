{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltools as ml\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('data/X_train.txt', delimiter=',')\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=',')\n",
    "X_test = np.genfromtxt('data/X_test.txt', delimiter=',')\n",
    "X, Y = ml.shuffleData(X, Y)\n",
    "Xtr,Xva,Ytr,Yva = ml.splitData(X,Y,0.5) \n",
    "X1,X2,Y1,Y2 = ml.splitData(X,Y,0.5) \n",
    "X3,X4,Y3,Y4 = ml.splitData(X2,Y2,0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPER FUNCTIONS\n",
    "def blendModelsPrediction(classifiers):\n",
    "\n",
    "    trainClassifiers(classifiers, X, Y)\n",
    "    predictions = predictClassifers(classifiers, X_test)\n",
    "    w = calculateWeight(predictions)\n",
    "    r = computesFinalBlendResult(predictions, w)\n",
    "    return r\n",
    "\n",
    "def threeStackedEnsemble(l1_classifiers, l2_classifiers, l3_classifiers):\n",
    "    ''' \n",
    "    l1_classifiers\n",
    "        trained: X1, Y1\n",
    "        predict: X3 -> l1_p_Y3\n",
    "        predict: X4 -> l1_p_Y4\n",
    "        predict: X_test -> l1_p_Y_test\n",
    "\n",
    "    l2_classifiers\n",
    "        trained: l1_p_Y3, Y3\n",
    "        predict: l1_p_Y4 -> l2_p_Y4\n",
    "        predict: l1_p_Y_test -> l2_p_Y_test\n",
    "\n",
    "    l3_classifiers\n",
    "        trained: l2_p_Y4, Y4\n",
    "        predict: l2_p_Y_test -> submit prediction Y_test\n",
    "    '''\n",
    "    trainClassifiers(l1_classifiers, X1, Y1)\n",
    "    l1_p_Y3 = stackResults(predictClassifers(l1_classifiers, X3))\n",
    "    l1_p_Y4 = stackResults(predictClassifers(l1_classifiers, X4))\n",
    "    l1_p_Y_test = stackResults(predictClassifers(l1_classifiers, X_test))\n",
    "\n",
    "    \n",
    "    trainClassifiers(l2_classifiers, l1_p_Y3, Y3)\n",
    "    l2_p_Y4 = stackResults(predictClassifers(l2_classifiers, l1_p_Y4))\n",
    "    l2_p_Y_test = stackResults(predictClassifers(l2_classifiers, l1_p_Y_test))\n",
    "\n",
    "    trainClassifiers(l3_classifiers, l2_p_Y4, Y4)\n",
    "    Y_test_prediction = predictClassifers(l3_classifiers, l2_p_Y_test)\n",
    "\n",
    "    return Y_test_prediction\n",
    "\n",
    "\n",
    "def convertToFinalPredictions(pred): #CONVERTS ALL PREDICITONS TO 0 AND 1\n",
    "    final_pred = []\n",
    "    for i in pred:\n",
    "        if i>0.5:\n",
    "            final_pred.append(1)\n",
    "        else:\n",
    "            final_pred.append(0)\n",
    "    return np.array(final_pred)\n",
    "\n",
    "\n",
    "def PrintValidationErrorofPredictions(preds): #PRINTS THE ERROR OF EACH PREDICTION ON THE VALIDATION DATA\n",
    "    i = 0\n",
    "    for p in preds:\n",
    "        fp = convertToFinalPredictions(p)\n",
    "        print(i,\"Prediction ERROR: \", 1-sum(fp==Yva)/float(len(Yva)))\n",
    "        i+=1\n",
    "\n",
    "def calculateWeight(predictions): #RETURNS THE WEIGHTS FOR EACH PREDICITON\n",
    "    numOfleaners = len(predictions)\n",
    "    predictions = np.array([np.array(convertToFinalPredictions(pred)) for pred in predictions])\n",
    "    weight = np.zeros(numOfleaners)\n",
    "    for indx, trueClass in enumerate(Yva):\n",
    "        for i in range(numOfleaners):\n",
    "            if predictions[i,indx] == trueClass:\n",
    "                weight[i] += 1\n",
    "            else:\n",
    "                weight[i] -= 1\n",
    "    return weight/sum(weight)\n",
    "\n",
    "\n",
    "def computeBlendErr(pred,weight): #COMPUTES AND PRINTS THE ERROR OF BLEND\n",
    "    result = 0\n",
    "    for i in range(len(pred)):\n",
    "        result += np.array(pred[i]) * weight[i]\n",
    "    PrintValidationErrorofPredictions([result])\n",
    "\n",
    "def computesFinalBlendResult(pred, weights): #COMPUTES BLEND FINAL RESULT AND RETURNS\n",
    "    result = 0\n",
    "    for i in range(len(pred)):\n",
    "        result += np.array(pred[i]) * weights[i]\n",
    "    return result\n",
    "\n",
    "\n",
    "def submitPredictions(pred): #PUTS YOUR PREDICTIONS INTO FinalPredictions.txt FOR SUBMISSION\n",
    "    Y_test = np.vstack((np.arange(X_test.shape[0]), pred)).T\n",
    "    # Output a file with two columns, a row ID and a confidence in class 1:\n",
    "    np.savetxt('FinalPredictions.txt', Y_test, '%d, %.2f',header='ID,Predicted', delimiter=',')\n",
    "\n",
    "\n",
    "def stackResults(predictions): #STACKS PREDICTIONS TO SINGLE ARRAY FOR TRAINING \n",
    "    #EACH COLUMN OF PREDICTIONS BECOMES A ROW FOR THE NEW TRAINING\n",
    "    new_outputs = []\n",
    "    for pred in predictions:\n",
    "        new_outputs.append([[j] for j in pred])\n",
    "    return np.array(np.hstack((np.array(new_outputs))))\n",
    "\n",
    "def finalSubmit(pred_tr, pred_te):\n",
    "    weights = calculateWeight(pred_tr)\n",
    "    print(\"final weights:\",weights)\n",
    "    final_prediction = computesFinalResult(pred_te, weights)\n",
    "    submitPredictions(final_prediction) \n",
    "\n",
    "def printModelAccuracy(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    n_scores = cross_val_score(model, X, Y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # report performance\n",
    "    print(model.__class__.__name__, 'Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "\n",
    "def trainClassifiers(classifiers, trainingX, trainingY):\n",
    "    for clf in classifiers:\n",
    "        print(\"TRAINING\", clf.__class__.__name__)\n",
    "        clf.fit(trainingX, trainingY)\n",
    "\n",
    "def predictClassifers(classifiers, data):\n",
    "    classifier_predictions = []\n",
    "    for clf in classifiers:\n",
    "        classifier_predictions.append(np.array(clf.predict_proba(data)[:, 1]))\n",
    "    return np.array(classifier_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=50)\n",
    "gb = GradientBoostingClassifier()\n",
    "lr = LogisticRegression(penalty='l1')\n",
    "svc = SVC(probability=True)\n",
    "nn = MLPClassifier()\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "l1_classifiers = [\n",
    "    AdaBoostClassifier(n_estimators=50), AdaBoostClassifier(n_estimators=50), AdaBoostClassifier(n_estimators=50),\n",
    "    GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),GradientBoostingClassifier(),LogisticRegression(penalty='l1'),LogisticRegression(penalty='l1'),LogisticRegression(penalty='l1'),SVC(probability=True),SVC(probability=True),SVC(probability=True),SVC(probability=True),SVC(probability=True),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),MLPClassifier(),KNeighborsClassifier(n_neighbors=2),KNeighborsClassifier(n_neighbors=2),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100)\n",
    "]\n",
    "\n",
    "\n",
    "l2_classifiers = [GradientBoostingClassifier(), LogisticRegression(penalty='l1'), MLPClassifier()]\n",
    "l3_classifiers = [RandomForestClassifier(n_estimators=1000)]\n",
    "\n",
    "\n",
    "# for clf in classifiers:\n",
    "#     printModelAccuracy(clf)"
   ]
  },
  {
   "source": [
    "final_stacked_prediction = threeStackedEnsemble(l1_classifiers, l2_classifiers, l3_classifiers)\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 67,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('TRAINING', 'AdaBoostClassifier')\n",
      "('TRAINING', 'AdaBoostClassifier')\n",
      "('TRAINING', 'AdaBoostClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'LogisticRegression')\n",
      "('TRAINING', 'LogisticRegression')\n",
      "('TRAINING', 'LogisticRegression')\n",
      "('TRAINING', 'SVC')\n",
      "('TRAINING', 'SVC')\n",
      "('TRAINING', 'SVC')\n",
      "('TRAINING', 'SVC')\n",
      "('TRAINING', 'SVC')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'KNeighborsClassifier')\n",
      "('TRAINING', 'KNeighborsClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'LogisticRegression')\n",
      "('TRAINING', 'MLPClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('TRAINING', 'AdaBoostClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'GradientBoostingClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n",
      "('TRAINING', 'RandomForestClassifier')\n"
     ]
    }
   ],
   "source": [
    "final_blend_prediction = blendModelsPrediction([AdaBoostClassifier(n_estimators=50),\n",
    "    GradientBoostingClassifier(),GradientBoostingClassifier(),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=100),RandomForestClassifier(n_estimators=1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.34203022 0.19286418 0.53705284 ... 0.44350903 0.8320947  0.48865463]\n[0.371 0.027 0.384 ... 0.258 1.    0.416]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7400970088924818"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "print(final_blend_prediction)\n",
    "print(final_stacked_prediction[0])\n",
    "float(sum(convertToFinalPredictions(final_blend_prediction)==convertToFinalPredictions(final_stacked_prediction[0])))/len(final_blend_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitPredictions(final_stacked_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}